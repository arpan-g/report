\chapter{Methodology}

This chapter explains the method developed to locate the sensors in a sensor grid, using the information about the locations of the vertices of the grid and data obtained from the sensors. Before we explain the method we introduce the definitions of the terms that 
we use in our thesis.\\
\begin{definition}{Neighboring sensors:}
 Two sensors are said to be neighbors if they have overlapping field of view.
\label{def:ns}
\end{definition}
\begin{definition}{Grid Adjacency Matrix:}
 We represent the sensor grid in the form of an adjacency matrix. Two vertices of the grid i and j are adjacent if the distance between them ($d_{i,j}$) is less than twice the radius(r) of the sensors field of view.

\[
GAM_{i,j} = 
\begin{cases}
1, &\text{ if } d_{i,j} < \text{  2r } \forall \text{ } i \ne j\\
0, & \text{otherwise}\\
\end{cases}
	\]
$d_{i,j}$  is the euclidean distance between the vertex i($x_i$,$y_i$) and j($y_j$,$y_j$).
\begin{equation*}
d_{i,j}=\sqrt{(x_i-x_j)^2 + (x_j-y_j)^2}
\end{equation*}
\label{def:GAM}
\end{definition}
From the definitions \ref{def:GAM} and \ref{def:ns} we can say that neighboring sensors will always be placed on neighboring vertices. 
\section{Feature}
Consider a m $\times$ n grid as shown in the figure \ref{fig:Grid}. There are $N= (m\times n)!$ ways in which the sensors can be uniquely placed on the grid. Out of these N ways we have to identify the actual arrangement of the sensors in the grid.  Along with the information of the vertex locations we also have the data from the sensors available. Using the sensor data along with information available about the grid we develop a method to identify the sensor lcoation of the grid\\
As neighboring sensors have an overlapping field of view, they observe the same events and thus are highly correlated.
On the raw signals of the PIR data stream we use a sliding window with 50\% overlap between the consecutive windows and compute the energy feature using the equation \ref{eq:energyEq}

\begin{equation}
\label{eq:energyEq}
E_s = {\sum_{n=0}^{k}{|x(n)|}^2}
\end{equation}
For a PIR binary data computing energy reduces to counting the number of triggers observed within the window.

\begin{figure}
\begin{tikzpicture}
\draw(0,0) node[circle,fill=black]{};
\draw(1.5,0) node[circle,fill=black]{};

\draw(0,2) node[circle,fill=black]{};
\draw(1.5,2) node[circle,fill=black]{};
\draw(0,3.5) node[circle,fill=black]{};
\draw(1.5,3.5) node[circle,fill=black]{};
\foreach \x in {0,1.5,2,2.5,3,3.5,4}
    \foreach \y in {0.5,1,1.5} 
  {
       \node [fill,circle,scale=0.3]  (\x\y) at (\x,\y) {};} 
\draw(4,0) node[circle,fill=black]{};
\draw(4,2) node[circle,fill=black]{};
\draw(4,3.5) node[circle,fill=black]{};
\foreach \x in {2,2.5,3,3.5}
    \foreach \y in {0,0.5,1,1.5,2,3.5} 
  {
       \node [fill,circle,scale=0.3]  (\x\y) at (\x,\y) {};} 
       
       \draw[thick](0,3.5) circle(1cm);
       \draw[|->|, rotate around with nodes={90:(0,3.5)}]
       (0,3.5)--(1,3.5) node[midway,fill=white,rotate with]{r};
       \draw[|<->|](0,3.5)--(1.5,3.5) node[midway,fill=white]{d};
       \draw[thick](1.5,3.5) circle(1cm);
       
\draw [decorate,decoration={brace,amplitude=10pt},xshift=-4pt,yshift=0pt]
(-0.5,0) -- (-0.5,3.5) node [black,midway,xshift=-0.6cm] 
{\footnotesize $M$};

\draw [decorate,decoration={brace,mirror,amplitude=10pt},xshift=-1em,yshift=-2em](0,-0.3) -- (4.5,-0.3) node [black,midway,yshift=-0.6cm]{\footnotesize N};


\end{tikzpicture}
\centering
\caption{A M $\times$ N grid having a sensor with field of view r and distance between the nodes being d.}
\label{fig:Grid}
\end{figure}



With the newly computed energy data stream, we compute the cross correlation between all the sensors using equation \ref{eq:corrcoeff}
\begin{equation}
\label{eq:corrcoeff}
r(x,y)=\frac{\sum_{i=1}^{n}(X_i-\overline{X})(Y_i-\overline{Y})}{\sqrt{\sum_{i=1}^{n}(X_i-\overline{X})^2}\sqrt{\sum_{i=1}^{n}(Y_i-\overline{Y})^2}} \\
\end{equation}
$X$ and $Y$ are data streams.\\
$\overline{X}$ and $\overline{Y}$ is the mean value of $X$ and $Y$ respectively.\\
$n$ is the number of samples.\\






\section{Grid Correlation Sum}
\label{sec:gcs}
Using the cross correlation values between the sensors, we define correlation matrix $R$ between the $n$ sensor nodes as shown in the equation \ref{eq:corrMatrix} .
\begin{equation}
\label{eq:corrMatrix}
\centering
R = 
\begin{bmatrix}
    r(1,1) & r(1,2) & \dots  & r(1,n) \\
    r(2,1) & r(2,2)  & \dots  & r(2,n) \\
    \vdots & \vdots  & \ddots & \vdots \\
    r(n,1) & r(n,2)  & \dots  & r(n,n)
\end{bmatrix}
\end{equation}\\
r($\alpha$,$\beta$) represents correlation value between the sensor $\alpha$ and $\beta$.\\

Using correlation matrix($R$) and grid adjacency matrix(GAM) we define a quantity called \textit{Grid Correlation Sum (GCS)} as given in the equation \ref{eq:gridCorrelationSum}. GCS represents the sum of correlation value of the sensor pair residing on neighboring vertices of the grid.
As the matrices are symmetrical along the diagonals we only consider the elements of the upper triangle of the matrices excluding the diagonal elements. 

\begin{equation}
\centering
\text{GCS}=\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}\text{R}(\phi(i),\phi(j))  \times \text{ GAM(i,j)}
\label{eq:gridCorrelationSum}
\end{equation}
$i,j$ represent $ i^{th}$ and $ j^{th}$ vertex on the grid.\\
$\phi$ is a mapping functions which gives the sensor present at vertex i.\\
$R(\alpha,\beta)$: correlation coefficient between the sensor $\alpha$ and $\beta$.\\
GAM:  Adjacency matrix of the grid as per definition \ref{def:GAM}.\\

We use GCS to identify the correct arrangement out of all the $N$ possible arrangement. If we compute  GCS for all the possible arrangements, the arrangement with the maximum GCS will represent the actual arrangement of the sensors on the grid.  
If two non neighboring sensors are kept on neighboring verticies or vice versa then the correlation value between those two sensors will be low and thus decreasing the GCS.
To illustrate this consider a sensor grid as shown in the figure \ref{fig:arrangement1}.
 It consists of 3 $\times$ 3 grid.  
GCS for the  the grid is :\\
\begin{equation*}
GCS_{1}=\text{r(1,2)+ r(1,4)+...r(2,3)+...r(5,6)+r(6,9)..+r(8,9)}
\end{equation*}

Now consider the arrangement shown in figure \ref{fig:arrangement2}, where the position of the sensors 3 and 6 are interchanged\\
\begin{equation*}
GCS_{2}=\text{ r(1,2)+r(1,4)+...+\textbf{r(2,6)}+...+\textbf{r(3,5)+r(3,9)}...+r(8,9)}
\end{equation*}

\begin{figure}[!ht]
\begin{floatrow}
\ffigbox{
\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=5}]
\foreach \y in {0,1,2}
 \foreach \x in {0,1,2}
{\pgfmathtruncatemacro{\label}{\x-3*\y+7}
\node[darkstyle](\x\y) at (1.5*\x,1.5*\y){\label};
}
 \foreach \x in {0,1,2}
    \foreach \y [count=\yi] in {0,1}  
      \draw (\x\y)--(\x\yi) (\y\x)--(\yi\x) ;

\end{tikzpicture}

\caption{Correct arrangement}
\label{fig:arrangement1}
}

\ffigbox{
\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=5}]

\draw[step = 1.5,thick ] (7.4,0) grid (10.5,3);
\node[circle,draw=black,fill=white!80!black,minimum size=5] (7) at (7.5,0) {7};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (4) at (7.5,1.5) {4};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (1) at (7.5,3) {1};

\node[circle,draw=black,fill=white!80!black,minimum size=5] (8) at (9,0) {8};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (5) at (9,1.5) {5};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (2) at (9,3) {2};

\node[circle,draw=black,fill=white!80!black,minimum size=5] (9) at (10.5,0) {9};
\node[circle,draw=black,fill=red!80!black,minimum size=5] (3) at (10.5,1.5) {3};
\node[circle,draw=black,fill=red!80!black,minimum size=5] (6) at (10.5,3) {6};
%\draw [<->,red] (3.east) to [out=60,in=60] (6.east);

\end{tikzpicture}

\caption{Incorrect arrangement}
\label{fig:arrangement2}
}
\centering

\end{floatrow}
\end{figure}

$GCS_{1}$ will be greater than $GCS_{2}$ as r(2,3) $>$ r(2,6) ,r(5,6)$>$r(3,5) and r(6,9) $>$ r(3,9) as sensors 2 and 6 , 3 and 5, 3 and 9 are non neighboring sensor nodes placed on neighboring vertices. Hence we can say that GCS will be maximum for a  mapping which maps sensors onto the grid accurately.\\
When the number of sensors is low we can identify the correct mapping by computing the GCS value for all the possible $N$ mappings. As the number of sensors increase the possible mappings to be checked also increases. Hence we need to find a method to reduce the search space.

\section{Maximum spanning Tree}

Having established a criterion to determine the right arrangement of sensors on the grid from  possible ${N}$ arrangements. The next step is to reduce the search space. For which we compute the maximum spanning tree (MST) for the correlation matrix ${R}$. 
If we consider ${R}$ as an adjacency matrix for a graph ${G}$, then the sensors represents the vertices and the correlation values between the sensors represents the weights of the edges between the corresponding sensors.
Now if we compute a maximum spanning tree for the graph, then the tree consists of all the sensor nodes connected to atleast one other node by an edge. The MST chooses an edge for every sensor such that the weight of the edge outgoing from the sensor $\alpha$ to sensor $\beta$ is the maximum among all the edges starting from sensor $\alpha$, in graph ${G}$. As the weights represent correlation values it implies that the maximum spanning tree connects a node to another with which it has the maximum correlation. As the correlation between the neighboring nodes is maximum we can say that MST connects the neighboring sensors.\\
 To compute the MST we make use of Prim's algorithm\cite{BLTJ:BLTJ1515}. As Prim's algorithm was originally developed to compute the minimum spanning tree we negate the weights for the correlation matrix and obtain the minimum spanning tree which will represent the maximum spanning tree for the original graph ${G}$. \\
As the sensors are placed on the grid and there exists an edge between the neighboring vertices of the grid. The MST over ${R}$ represents one of the spanning tree for the grid. As illustrated in the figure \ref{fig:MST}.
It is possible that for a given grid there may be several spanning trees with the same structure. 
Figure \ref{fig:variousMappings} shows few of the spanning tree similar to the MST obtained for the correlation matrix.
If we compute all the possible spanning trees for the grid which maintains the same structure as that of the maximum spanning tree for the correlation matrix and map each vertex on the MST to the corresponding spanning tree of the grid as shown in the figure \ref{fig:mapping}, we obtain several possible mappings of the sensors to grid location.Among the possible mappings we have to choose the correct arrangement. To choose the true arrangement of the sensor on the grid we make use of  GCS. The number of arrangements that are obtained from this method is lesser than the ${N}$  possible arrangements that we had to check previously. \\
The main reason for decrease in the possible mapping can be explained as follows:
When we are computing various mappings between the sensors maximum spanning tree and spanning tree for the grid suppose we assign one of the nodes($S_x$) on the  spanning tree to one of the nodes on the grid($G_x$) then in the next step the node which is connected to $S_x$ can be mapped only to the neighboring nodes of the grid node $G_x$ .









%Having established a method to determine the true arrangement of the sensor nodes on the grid from all the possible \textbf{N} arrangements, the next step is to prune the possible arrangements. \\
%From the definitions of neighboring sensors and neighboring vertices we can say that two neighboring sensors will always be placed on the neighboring vertices. From the grid adjacency matrix we can determine the neighboring vertices of a vertex. If we can determine the neighboring sensor nodes then we can prune the number of possible arrangements by using the constraints that only neighboring sensors can occupy the neighboring vertices. 




%If the neighbors of a sensor are known , the sensors occupying the neighboring vertices on the grid has to be occupied by it's neighboring sensors .
%The neighboring vertices of a vertex \textbf{i} on which a sensor \textbf{a} is located should be occupied by the neighbors of sensor \textbf{a}.
%Thus resulting in the reduction of the number of possible arrangements.

%If we know which are all the neighbors of a sensor then when a sensor is placed on the vertex of a sensor, we know that the neighboring vertex on the grid should only be occupied by it's neighboring nodes. 

%Though the correlation value between two neighboring nodes are high compared to the correlation value between the non neighboring nodes, finding a threshold to differentiate between the neighboring and non neighboring nodes when the arrangement is not known is non trivial.\\
%Although we might not be able to identify all the neighboring nodes even if we are able to find a minimum of one neighboring node per node we will be able to reduce the number of mappings that needs to be checked. To achieve this we calculate the maximum spanning tree for the correlation matrix \textbf{R}.

%If we consider R as an adjacency matrix with each sensor representing a vertex and the correlation value between the sensors representing the edge weight between them. Then the maximum spanning tree for such a graph will connect all the vertices together such that the total weight for the edges in the tree is maximum. 


%A maximum spanning tree has an edge between 2 nodes which have high correlation matrix compared with the other nodes. Therefore if an edge exists between two nodes in the maximum spanning tree then we can say that those two nodes are neighboring nodes.\\
%To compute the maximum spanning tree we use Prim's algorithm \cite{BLTJ:BLTJ1515}.Originally  Prim's algorithm is designed to compute the minimum spanning tree for a graph. In order to compute the maximum spanning tree the correlation matrix is negated and given as the input to the algorithm. The minimum spanning tree %obtained from negated weights is the maximum spanning tree for the original weights.This maximum spanning tree represents one of the spanning tree for the grid as can be seen from the figure \ref{fig:MST}. 

%A Maximum spanning tree chooses an edge which has the maximum weight starting from the vertex, among all the vertices that are present. As in our case the vertices represent the sensor nodes and edge weights is the correlation value between the sensor nodes. So  edge that is originates from the node connects to a node which is it's neighbor . As this step is carried on for every sensor , we have an edge originating from the sensor node, lets call it  the start node ending a sensor node, lets call it end node. The start node has the highest correlation with the end node. As the correlation values who are neighbors are the highest, we can safely tell %that this edge is connecting the start node to a neighbor of the start node.

%While computing the maximum spanning tree an edge from a node under consideration is chosen which has the maximum weight originating from it. out of all the edges the node has, the edge with the maximum weight is chosen. 

%While computing a maximum spanning tree an edge from a node is chosen which has the maximum weight compared to the other edges of the node under consideration. This process is repeated for all the nodes that are present in the graph. In our case each vertex represents a sensor and the edge weight is given by the cross %correlation value between the two sensors. Since for every node a maximum correlation value is chosen and as the correlation value between the neighbors is maximum we can say that in a maximum spanning tree two  neighboring sensors are connected. 

\begin{figure}[!ht]
\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=5}]
\node[darkstyle]{1}
	child{node[darkstyle]{2}}
    child{node[darkstyle]{4}
    	child{node[darkstyle]{5}
	        child{node[darkstyle]{6}
            	child{node[darkstyle]{3}}
                child{node[darkstyle]{9}}}}
                child{node[darkstyle]{7}
                child{node[darkstyle]{8}}}};
\end{tikzpicture}
\qquad \qquad \qquad
\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=5}]
\foreach \y in {0,1,2}
 \foreach \x in {0,1,2}
{\pgfmathtruncatemacro{\label}{\x-3*\y+7}
\node[darkstyle](\x\y) at (1.5*\x,1.5*\y){\label};
}
\draw (01)--(02) (02)--(12) (01)--(11) (11)--(21) (21)--(22)
(21)--(20) (00)--(01) (00)--(10);


\end{tikzpicture}
\caption{A maximum spanning tree incident on the grid}
\label{fig:MST}
\end{figure}

\begin{figure}[!ht]

\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=5}]
\node[darkstyle]{G3}
	child{node[darkstyle]{G2}}
    child{node[darkstyle]{G6}
    	child{node[darkstyle]{G5}
	        child{node[darkstyle]{G4}
            	child{node[darkstyle]{G7}}
                child{node[darkstyle]{G1}}}}
                child{node[darkstyle]{G9}
                child{node[darkstyle]{G8}}}};
\end{tikzpicture}
\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=5}]
\node[darkstyle]{G7}
	child{node[darkstyle]{G4}}
    child{node[darkstyle]{G8}
    	child{node[darkstyle]{G5}
	        child{node[darkstyle]{G2}
            	child{node[darkstyle]{G3}}
                child{node[darkstyle]{G1}}}}
                child{node[darkstyle]{G9}
                child{node[darkstyle]{G6}}}};
\end{tikzpicture}
\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=5}]
\node[darkstyle]{G9}
	child{node[darkstyle]{G8}}
    child{node[darkstyle]{G6}
    	child{node[darkstyle]{G5}
	        child{node[darkstyle]{G4}
            	child{node[darkstyle]{G1}}
                child{node[darkstyle]{G7}}}}
                child{node[darkstyle]{G3}
                child{node[darkstyle]{G2}}}};
\end{tikzpicture}
\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=5}]
\node[darkstyle]{S1}
	child{node[darkstyle]{S2}}
    child{node[darkstyle]{S4}
    	child{node[darkstyle]{S5}
	        child{node[darkstyle]{S6}
            	child{node[darkstyle]{S3}}
                child{node[darkstyle]{S9}}}}
                child{node[darkstyle]{S7}
                child{node[darkstyle]{S8}}}};
\end{tikzpicture}
\caption{Various spanning tree for the grid with similar structure of the MST of the correlation matrix.}
\label{fig:variousMappings}
\end{figure}







\begin{figure}[!ht]
\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=5}]
\begin{scope}
\node[darkstyle](G9){G9}
	child{node[darkstyle](G8){G8}}
    child{node[darkstyle](G6){G6}
    	child{node[darkstyle](G5){G5}
	        child{node[darkstyle](G4){G4}
            	child{node[darkstyle](G1){G1}}
                child{node[darkstyle](G7){G7}}}}
                child{node[darkstyle](G3){G3}
                child{node[darkstyle](G2){G2}}}};
\end{scope}
\qquad
\begin{scope}[shift={(6,0)}]
\node[darkstyle](S1){S1}
	child{node[darkstyle](S2){S2}}
    child{node[darkstyle](S4){S4}
    	child{node[darkstyle](S5){S5}
	        child{node[darkstyle](S6){S6}
            	child{node[darkstyle](S3){S3}}
                child{node[darkstyle](S9){S9}}}}
                child{node[darkstyle](S7){S7}
                child{node[darkstyle](S8){S8}}}};
\end{scope}
\draw[loosely dotted,very thick,->] (G9)to[out=0-15,in=195](S1);
\draw[loosely dotted,very thick,->] (G8)to[out=0-15,in=195](S2);
\draw[loosely dotted,very thick,->] (G6)to[out=15,in=165](S4);
\draw[loosely dotted,very thick,->] (G5)to[out=0-15,in=195](S5);
\draw[loosely dotted,very thick,->] (G4)to[out=0-15,in=195](S6);
\draw[loosely dotted,very thick,->] (G1)to[out=0-15,in=195](S3);
\draw[loosely dotted,very thick,->] (G7)to[out=15,in=165](S9);
\draw[loosely dotted,very thick,->] (G3)to[out=15,in=165](S7);
\draw[loosely dotted,very thick,->] (G2)to[out=15,in=165](S8);
\end{tikzpicture}
\caption{Mapping between the grid spanning tree and the MST for the correlation matrix}
\label{fig:mapping}
\end{figure}

% Graph monomorphism 

\section{Graph Matching} 

In the previous section we obtain a maximum spanning tree from the correlation matrix and saw how this represents a spanning tree for the grid. We also saw that there can multiple spanning tree whose structure is similar to the MST obtained for the correlation matrix. In this section we describe method to obtain all the possible spanning trees that has the same structure as the MST obtained from the correlation matrix of the sensors.
The task of checking if a pattern graph H is contained in a base graph G and obtaining all the mappings from G to H is a standard problem of graph matching.\\

A graph matching process between two graphs $G$ = $(V_G,E_G)$ and H = $(V_H,E_H)$ consists of determining a mapping M which associates nodes of the graph G to H and vice versa. Different constraints can be imposed onto M which results in different mapping types: monomorphism, isomorphism, graph-subgraph isomorphism are the most popular ones. Our problem falls under the category of graph monomorphism . \\
Two graphs 
 $G =( V_G, E_G)$ and
 H =$( V_H, E_H)$  are monomorphic  if and only if there exists an injective (node)
mapping $\phi (V_G) \rightarrow  V_H$ : for which $\forall v,w \in V_G:(v,w) \in E_G \Rightarrow (\phi((v),\space \phi(w)) \in E_H.$\\  

Monomorphism is often confused with subgraph isomorphism. Monomorphism is a weaker kind of subgraph isomorphism. \\
Two graphs  $G =( V_G, E_G)$ and
 H =$( V_H, E_H)$  are sub graph isomorphic  if and only if there exists an injective (node)
mapping $\phi( V_G) \rightarrow  V_H$ : for which $\forall \text{ v,w} \in V_G:(v,w) \in E_G \Leftrightarrow (\phi((v),\space \phi(w)) \in E_H.$ 
The relationship between edges of the graphs are equivalence for subgraph isomorphism, and for Monomorphism  relationship  is an implication.\\
A problem of finding all the Monomorphisms of the pattern graph into the base graph is defined as Monomorphism problem. Graph Monomorphism is a NP-Complete problem \cite{Garey:1979:CIG:578533}. 
\subsection{Related Work}

Graph matching is widely used in pattern recognition and image processing applications. Graph matching also finds its application in the field of biomedical and biological applications. 
Most of the algorithms for graph matching are based on some form of tree search with backtracking.
 The basic idea is that the partial mapping (initially empty) is iteratively expanded by adding to it new pairs of matched nodes; the pairs are chosen based on some conditions employed to satisfy the conditions of the matching type.

The key principle is that there will be a partial mapping(initially empty)and is expanded iteratively by adding to it a new pairs of matched node. The matched nodes are chosen based on the certain conditions that depend on the matching type.

The first prominent and one of the most widely used algorithm in the area of graph matching was proposed by \citeauthor{Ullmann:1976:ASI:321921.321925} \cite{Ullmann:1976:ASI:321921.321925}. Ullmann algorithm addresses the problem of graph isomorphism, sub graph isomorphism , graph monomorphism. Ullmann algorithm is based on  depth first search with backtracking. To prune unfruitful matches the author proposes a refinement procedure, which employ conditions based on the knowledge of the adjacent nodes and the degree of the nodes that are being matched. 
\citeauthor{4308468} in \cite{4308468} propose a graph monomorphism algorithm. The authors formulate the graph monomorphism problem as a minimum weight clique problem of weighted nets . The major drawback of the algorithm is that the algorithm uses a $N^2 \times N^2$ matrix to represent netgraph
. N representing the number of nodes of the largest graph. As a result of this only small graphs can be dealt with using the algorithm.  
A more recent algorithm for graph isomorphism, subgraph isomorphism and monomorphism was proposed by \citeauthor{906251} in \cite{906251}, popular as VF algorithm. The authors define a heuristic that is based on the analysis of sets of nodes adjacent to the ones already considered in the partial mapping. The authors further improved the algorithm in 2001 in their paper \cite{cordella2001improved}. 
The authors proposed a modification to the algorithm and called it VF2. The authors introduce a method to restore data structure, which enabled them to reduce the memory consumption from $O(N^2)$ to O(N) where N is the number of nodes in the graph, thus enabling the algorithm to work with large graphs.
In our work we use the VF2 algorithm to obtain the mappings between the spanning tree and grid graph.

\subsection{VF2}

In this section we give a brief description about VF2 algorithm.\\

\begin{figure}

\begin{algorithm}[H]
\begin{algorithmic}
 \LState  \textbf{Procedure} Match(s)\\
\textbf{INPUT:}  an intermediate state s; the initial state $s_0$ has $M(s_0)=\emptyset$\\
\textbf{OUTPUT:} the mappings between two graphs\\
\textbf{Match(s)}\\
 \textbf{IF} M(s) covers all the nodes of $G_2$ \textbf{THEN}\\
\quad \textbf{OUTPUT} M(s)\\
\textbf{ELSE}\\
 \quad    Compute the set P(s) of the pairs of candidates for inclusion in M(s)\\
\quad\textbf{FOREACH} (n,m) $\in$ P(s)\\
\quad\quad\textbf{IF} F(s,n,m) \textbf{THEN}\\
\quad\quad\quad	Compute the state s' obtained by adding (n,m) to M(s)\\
\quad\quad\quad\textbf{CALL} Match(s')\\
\quad\quad\textbf{ENDIF}\\
\quad\textbf{ENDFOREACH}\\
\quad Restore data structure\\
\textbf{ENDIF}\\

\end{algorithmic}
\end{algorithm}
\caption{Pseudo code for VF2 algorithm}
\label{fig:VF2}
\end{figure}


% VF2 explanation 
VF2 algorithm is a graph matching algorithm to solve graph isomorphism, monomorphism and  subgraph isomorphism problem. VF2 uses depth search first method to iterate through all the nodes and recursive backtracking technique to check for all the possible mappings. A process of matching 
a base graph G to a pattern graph H consists of determining a mapping M which associate nodes of base graph (G) with nodes of the pattern graph (H) and vice versa, with some constraints.
Mapping is expressed as a set of pairs of node (n,m) with n $\in$ G and m $\in$ H. 
In VF2 algorithm the process of finding the mapping function is described by a  State Space Representation (SSR). Each state s of the matching process can be associated to a partial mapping solution M(s),
which contains only a subset of M. A transition from current state(s) to the next state(s') represents the addition of a mapping (n,m) to the state s.

VF2 algorithm introduces a set of rules which helps to prune the number of possible SSR that needs to be checked before obtaining a valid mapping. Figure \ref{fig:VF2} gives a high-lvel description of the VF2 algorithm.
There are 3 important functionalities in the algorithm: 
\begin{itemize}
\item generation of possible mappings(P(s)) .
\item checking of the validity of the mapping(F(s,n,m)).
\item Restore data structure.
\end{itemize}


%Data graph (G), Querry graph(Q)

\subsection{Computation of candidate pair set P(s)}
This section explains the method to compute the candidate pair set P(S) for an undirected graph G and H. 
For every intermediate state s the algorithm computes P(s), a set of possible mapping pairs. For each pair p belonging to P(s) the feasibility of its addition F(s,n,m) is checked : if the check is successful the next state $s' = s \cup p$ and the whole process recursively applies to s'.

To compute P(S) set $T_1(s)$ and $T_2(s)$ are defined for Graph G and H respectively. $T_1$ and $T_2$ are the set of  nodes in G and H, which are neighbors of the set of nodes included in the partial mapping state M(s) but are not included in M(s).
Set P(s) will be made of all the the node pairs(n,m) with n being a node in $T_1$ with the smallest label  and m being a node in $T_2$ . If  $T_1$ and $T_2$ sets are empty then the set P(s) be calculated by using the sets of nodes not contained in either G(s), H(s).

\subsection{Feasibility Rules}
Feasibility Rules are used to check the consistency of the partial solution s' obtained by adding nodes n,m and prune the search tree. The functionality of the rules are as explained below.

In vf2 algorithm, those candidates(m,n) are pruned if m is not connected to already matched nodes in $G_q$
(i.e nodes of $G_q$ included in M(s)).
Subsequently, the pruning step also removes those node-pairs(m,n) in which n is not connected to the matched 
nodes in the data Graph G. These pruning rules assume that the query and data graph are connected.\\

The algorithm also compares the number of neighboring nodes of each n and m that are connected to nodes in M(s) but are not
included in M(s). The number of such nodes in the data graph must be greater than or equal to the number of such nodes in the query graph.\\

Finally the number of neighboring nodes of each of n and m that are not directly connected to nodes in M(s) are compared. The number of 
such nodes in the data graph must be greater than or equal to the number of such nodes in the query graph.

\subsection{Restore data structure}
In VF2 algorithm all the vectors that are used to store data have the following property: If an element is non-null in a state s, it will remain non-null in all states descending from s. This property, together with the depth-first strategy of the search is, is used to avoid the need to store a different copy of the vectors for each state: when the algorithm backtracks, it restores the previous value of the vectors. Hence the space complexity of VF2 algorithm is of the order O(N). This is illustrated in the figure \ref{fig:memManagement}.As can be seen at the last state if a variable was created at every state then we will end up with $N^2$ variables.

\begin{figure}
\includegraphics[scale=0.5]{./pics/memManagement.png}
\caption{Memory cells occupied at each state with and without restore data}
\label{fig:memManagement}
\centering
\end{figure}

\subsection{Computation Complexity}
Computational complexity of the VF2 depends on two factors: 
\begin{itemize}
\item The time required to calculate the feasibility of every SSR's , computation of the node pair mappings.
\item Number of SSR visited.
\end{itemize}

According to the authors the former has a time complexity of $O(N)$ . For the latter the authors consider a best case; where only only one of the potential mappings are feasible which makes the computation complexity $O(N)$ and thus making the overall complexity $O(N^2)$. In the worst case, the algorithm has to explore all the states. This can happen when every node is connected to every other node (base graph is a complete graph) and the graph exhibits strong symmetry. The authors show that the complexity in such a condition is $O(N!)$ and thus making the total complexity $O(N!N)$.
In our case we show the order of complexity for a 8-neighborhood grid. The worst case for such a grid will arise when at every stage of the search tree the algorithm has to explore every possible branch. Since it's a 8-neighborhood grid all the nodes except the ones at the edges of the grid will have 8 neighbors. As one of the neighboring node would be the parent node the node at stage $i$ will have $7^{i}$ possibilities to explore and stage N there will be $7^n$ possibilities to explore . The total number of states to explore will be given by the sum:\\

\begin{align*}
1 + 7 + 7^2+ . . . . .+7^i+....7^n\\
\text{This represents a geometric progression with a= 1, r =7.}\\
\text{Sum of a geometric progression is given by:}\\
S_{n}=\frac{a(r^n-1)}{r-1}\\
S_{n}=\frac{7^{n+1} -1}{7-1} \\
\text{When n is large}\\
S_{n} \approx 7^N\\
\end{align*}

Thus computational complexity is $O(7^NN)$

\begin{figure}
\includegraphics[scale=0.5]{./pics/tree.png}
\caption{All the visited states in case of a 8 neighborhood grid with n nodes.}
\label{fig:ccO}

\end{figure}

\section{Determination of sensor placement}
\label{ref:rotationalSym}
After we obtain the various mappings. We need to decide which out of the various mappings gives the actual placement of the sensors on the grid. To identify the correct mapping we compute GCS as explained in section \ref{sec:gcs}. We calculate the grid correlation sum for all the mappings obtained and the mappings which gives the maximum sum will be the actual placement of the sensors on the grid. 
\subsection{Limitations}

Our method  can identify the location of the sensors upto rotational symmetry. As the $GCS$ remains the same for a sensor arrangement which is rotationally symmetrically to the original sensor arrangements. 
As seen in the two arrangements that are shown in the figure \ref{fig:symm} and \ref{fig:rotationalSymm}. Therefore when we pick the mappings which has the highest GCS we get multiple mappings. These mappings include the actual arrangement and arrangement which are rotationally symmetric it.

\begin{figure}[!ht]
\begin{floatrow}
\ffigbox{
\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=5}]
\foreach \y in {0,1,2}
 \foreach \x in {0,1,2}
{\pgfmathtruncatemacro{\label}{\x-3*\y+7}
\node[darkstyle](\x\y) at (1.5*\x,1.5*\y){\label};
}
 \foreach \x in {0,1,2}
    \foreach \y [count=\yi] in {0,1}  
      \draw (\x\y)--(\x\yi) (\y\x)--(\yi\x) ;

\end{tikzpicture}

\caption{Actual arrangement}
\label{fig:symm}
}


\ffigbox{
\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=5}]

\draw[step = 1.5,thick ] (7.4,0) grid (10.5,3);
\node[circle,draw=black,fill=white!80!black,minimum size=5] (7) at (7.5,0) {9};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (4) at (7.5,1.5) {6};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (1) at (7.5,3) {3};

\node[circle,draw=black,fill=white!80!black,minimum size=5] (8) at (9,0) {8};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (5) at (9,1.5) {5};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (2) at (9,3) {2};

\node[circle,draw=black,fill=white!80!black,minimum size=5] (9) at (10.5,0) {7};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (3) at (10.5,1.5) {4};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (6) at (10.5,3) {1};
%\draw [<->,red] (3.east) to [out=60,in=60] (6.east);

\end{tikzpicture}

\caption{Sensors arrangement rotationally symmetric to the actual arrangement }
\label{fig:rotationalSymm}
}
\centering

\end{floatrow}
\end{figure}


\subsection{Special case when the grid is $n \times 2$ or $2 \times n$}
Consider a sensor $2 \times n$ sensor grid with diagonally opposite nodes connected as shown in the figure \ref{fig:ntime2}. These grid structure posses a special case of symmetry. As shown in the  figure \ref{fig:ntime2Sym} the nodes 1 and 2 are interchanged; it is as if the whole structure was rotated with  edge (1,2) fixed. The diagonally opposite edges (1,3) in figure \ref{fig:ntime2} becomes non diagonal edges in the figure \ref{fig:ntime2Sym}. To overcome this error we use weighted grid adjacency matrix instead of a binary grid adjacency matrix. We compute \textit{Weighted Grid Adjacecny Matrix (WGMA)} as follows:
First we normalize the distance between all the sensor nodes which has an edge between them in the $GAM$ by dividing all the distances between the sensor nodes by the minimum distance$(d_{min})$ that exists between the nodes in the entire grid. Then we take the reciprocal of the normalized distance to obtain the WGAM. All the members of the WGAM value lies between the 0 and 1. 1 signifying the 2 sensors are close to each other and 0 signifying that the 2 sensors are far away from each other.\\
\[
WGAM_{i,j} = 
\begin{cases}
\dfrac{d_{min}}{d_{i,j}}, &\text{ if } GAM_{i,j} = 1\\
0, & \text{otherwise}\\
\end{cases}
\]


We use $WGAM$ instead of $GAM$ to compute $GCS$ in equation \ref{eq:gridCorrelationSum}. The reasoning behind the use of WGAM matrix instead of the GAM is that we hypothesize that the correlation values for the sensor which are closer is higher than the one compared to sensors which are further apart. By assigning weights to the edges in this manner, more importance is given to the edges between the sensors that are closer to the each other. Doing so the sensors which are close by contribute  more to the $GCS$ . 
Now if we consider arrangement as shown in the figure \ref{fig:ntime2} and \ref{fig:ntime2Sym} though there $GCS$ remain the same with $GAM$, $GCS$ won't remain the same when $WGAM$ is used. The contribution of the correlation between the sensors placed on the non diagonal edges are more compared to the contribution made by the diagonal edges. Therefore if we place the non diagonally located sensors on the diagonals of the grid $GCS$ decreases. Thus by using a weighted grid adjacency matrix we are able to obtain the mapping of the sensors onto the grid upto rotational symmetry.

\begin{figure}
\begin{floatrow}
\ffigbox{

\begin{tikzpicture}

\node[circle,draw=black,fill=white!80!black,minimum size=5] (1) at (0,0) {1};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (3) at (1.5,0) {3};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (5) at (3,0) {5};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (7) at (4.5,0) {7};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (2) at (0,1.5) {2};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (4) at (1.5,1.5) {4};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (6) at (3,1.5) {6};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (8) at (4.5,1.5) {8};
\draw (1)--(2) (1)--(3) (1)--(4) (2)--(3) (3)--(4) (4)--(6)   (2)--(4)  (4)--(5) (3)--(6) (3)--(5) (5)--(6) (6)--(7) (5)--(8) (5)--(7) (7)--(8) (8)--(6);
\end{tikzpicture}
\caption{Actual arrangement of $2 \times 4$ grid.}
\label{fig:ntime2}
}

\ffigbox{
\begin{tikzpicture}
\node[circle,draw=black,fill=white!80!black,minimum size=5] (2) at (0,0) {2};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (3) at (1.5,0) {3};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (5) at (3,0) {5};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (7) at (4.5,0) {7};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (1) at (0,1.5) {1};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (4) at (1.5,1.5) {4};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (6) at (3,1.5) {6};
\node[circle,draw=black,fill=white!80!black,minimum size=5] (8) at (4.5,1.5) {8};
\draw (1)--(2) (1)--(3) (1)--(4) (2)--(3) (3)--(4) (4)--(6)   (2)--(4)  (4)--(5) (3)--(6) (3)--(5) (5)--(6) (6)--(7) (5)--(8) (5)--(7) (7)--(8) (8)--(6);


\end{tikzpicture}
\caption{Incorrect arrangement of $2 \times 4$ grid with the same $GCS$ values.}
\label{fig:ntime2Sym}
}
\centering
\end{floatrow}
\end{figure}


\section{Summary}
In this chapter we describe a method to locate the sensor on the grid making use of sensor data and grid vertices information up-to rotational symmetry. Figure \ref{fig:Summary} gives the summary of steps involved in the form of a flowchart. 

\begin{figure}
\includegraphics[scale=0.6]{./pics/methodSummary.png}
\caption{Flowchart for the method developed}
\label{fig:Summary}
\centering
\end{figure}



 






 


